This is forked from the arm tracking project originally posted by seanshi007:
https://github.com.seanshi007/kinect_based_arm_tracking.git

Necessary components:
1-2 baxter robots(real or in gazebo)
Microsoft Kinect 2.0 or bag files with /tf data to replay

How to run this demo with VXLab Rosie:
    1. Turn on Rosie ensure that Kinect 2.0 (kinrosie) is running correctly

For Local Use (No networking, One Rosie and one Microsoft Kinect 2.0):
    2. In a terminal run:
       rosrun kinect_based_arm_tracking tf_user_tracker.py
       rosrun kinect_based_arm_tracking tf_listen_v8_newpub.py
       rosrun kinect_based_arm_tracking tf_listen_v8_controller.py
    3. Wait for Rosie to raise arms to the starting position (T-pose)
    4. Start gesturing in front of the kinect and rosie should attempt to replicate your gestures.

For fully networked usage, i.e. 2-way communication between two Rosie/Kinects:
    2. On both machines, in a terminal run:
       rosrun kinect_based_arm_tracking tf_user_tracker.py
       rosrun kinect_based_arm_tracking tf_listen_v8_socketpub.py
       rosrun kinect_based_arm_tracking tf_listen_v8_controller.py
    3. If rosbridge_websocket.py is not already running on the master node, run:
       roslaunch rosbridge_server rosbridge_websocket.launch
    4. Wait for Rosie to raise arms to the starting position (T-pose)
    5. At this point Rosie should not respond to user motion in kinect sensor or from /tf bag file playback.
    6. Edit ottserver.html: At the lines where ros1 and ros2 are defined, change the url field to the hostnames or ip addresses of the two Rosie units. (In vxlab, works best with mb, as mb runs the websocket server at boot.)
    7. Save ottserver.html and open in the browser, open browser console to verify that the server was able to connect to both rosbridge_websocket nodes, if so, both Rosie units should now be able to recieve data from each other's kinect sensors.
